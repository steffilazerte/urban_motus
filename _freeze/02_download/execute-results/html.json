{
  "hash": "c9bfa08c643073253620fab19d10472d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Download/Update Data & Transform\nfreeze: auto\n---\n\n\nIn this step we download, or update, our Motus SQLite databases.\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"XX_setup.R\")\n```\n:::\n\n\nThis step can take a lot of time and it may not be necessary to be constantly updating the data bases. Set `update <- TRUE` to update, `update <- FALSE` to just check the number of new observations.\n\nNote that in addition to downloading new data, `update` will also rerun all the \nprocessing of this data into feather `hits` and `runs` (See [Save to Arrow/Feather](save-to-arrow-feather)].\n\n\n::: {.cell}\n\n```{.r .cell-code}\nupdate <- FALSE\n```\n:::\n\n\n## Status\n\nGet the status of each project (i.e. how much data left to download?)\n\n- This will create new `project-XXX.motus` SQLite data bases for us if it \n  doesn't already exist (but will not download the data)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(update) {\n  status <- data.frame(proj_id = projects, \n                       file = paste0(\"Data/Raw/project-\", projects, \".motus\")) |>\n    mutate(status = map2(\n      proj_id, file, \n      \\(x, y) tellme(x, dir = \"Data/Raw\", new = !file.exists(y)))) |>\n    unnest(status) |>\n    mutate(currentMB = file.size(file)/1024/1024,\n           newMB = numBytes/1024/1024)\n  \n  select(status, -file, -numBytes) |>\n    relocate(currentMB, newMB, .after = proj_id) |>\n    arrange(proj_id) |>\n    gt() |>\n    fmt_number(decimals = 0) |>\n    tab_spanner(label = \"New Data\", columns = -c(proj_id, currentMB)) |>\n    gt_theme()\n}  \n```\n:::\n\n\n## Download data\n\n**If this is the first time running, it will take time!**\n\n- `tagme()` without arguments will update all databases in the folder\n- we can run this intermittently to update the databases as new data arrives\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(update) tagme(dir = \"Data/Raw\")\n```\n:::\n\n\n## Clean up\n\nHere we'll deal with deprecated batches and metadata.\n\nFirst we'll load the database connections.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbs <- map(projects, \\(x) tagme(x, dir = \"Data/Raw\", update = FALSE))\n```\n:::\n\n\n\n## Remove deprecated batches\n\nDeprecated batches are removed from the Motus server, but are still present in data that was previously downloaded. This step cleans up the database.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(update) {\n  iwalk(dbs, \\(x, y) {\n    message(\"\\nProject \", y)\n    deprecateBatches(x, ask = FALSE)\n  })\n}\n```\n:::\n\n\n\n## Update metadata\n\nHere we'll update the metadata associated with *all* projects so that we \nhave better information on different tags, receivers, etc. which these projects\nmay be interacting with.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(update) {\n  iwalk(dbs, \\(x, y) {\n    message(\"\\nProject \", y)\n    metadata(x)\n  })\n}\n```\n:::\n\n\n## Save to Arrow/Feather\n\nNow we'll create some custom views and save to [feather](https://arrow.apache.org/)\nformat (see also the [R4DS introduction to Apache Arrow](https://r4ds.hadley.nz/arrow#introduction)).\n\nFeather files are very fast to work with and I've found that they are a bit simpler\nto deal with when we're mostly concerned with the hits/runs tables.\n\nSo we'll spend a bit of time converting them here so the following steps are faster.\n\n\n### Custom tables\n\nNormally, we would use the `allruns` view from our .motus data bases. \n\nHowever, this view includes a lot of data that we don't need and I find it faster \nto pull out the variables we're interested by hand using a custom function,\n`custom_runs()`. \n\n:::{.callout-important title=\"Caution\"}\nThat being said, there are some complex joins going on in the `allruns` view.\nI have replicated the relevant ones here, and while I reasonably\nsure these yield the same data, if there are is any hint that they're not exactly\nthe same, we should double check.\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\nThis function is faster than collecting the `allruns` view\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time(tbl(dbs[[\"607\"]], \"allRuns\") |> collect())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  0.780   0.309   1.099 \n```\n\n\n:::\n\n```{.r .cell-code}\nsystem.time(custom_runs(dbs[[\"607\"]]) |> collect())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  0.395   0.000   0.395 \n```\n\n\n:::\n:::\n\n\nGet the custom run tables for all databases\n\n::: {.cell}\n\n```{.r .cell-code}\nif(update) runs <- map(dbs, custom_runs)\n```\n:::\n\n\n\n### Export\n\nNow save these as Arrow/Feather format (but first clear the original data, as we'll be \nsaving to Arrow by splitting the data across multiple files, so don't want any conflicts).\n\nOn the way we'll also create some added date and time columns.\n\nThis should run reasonably fast. \n\n::: {.cell}\n\n```{.r .cell-code}\nif(update) {\n  unlink(\"Data/Datasets/runs/*\", recursive = TRUE)\n  iwalk(runs, \\(x, i) {\n    message(i)\n    x |>\n      mutate(proj_id = as.integer(i)) |>\n      collect() |>\n      mutate(timeBegin = as_datetime(tsBegin),\n             timeEnd = as_datetime(tsEnd),\n             dateBegin = as_date(timeBegin),\n             dateEnd = as_date(timeEnd),\n             monthBegin = month(timeBegin),\n             yearBegin = year(timeBegin),) |>\n      group_by(proj_id) |>\n      write_dataset(path = \"Data/Datasets/runs/\", format = \"arrow\") \n  })\n}\n```\n:::\n\n\n\n\nThe thing with splitting data across multiple files is that we don't want files to be\n<20MB or >2GB and we want to avoid too many files (< 10,000).\n\nSo let's double check that we have reasonable file sizes and numbers.\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(files = list.files(\"Data/Datasets/runs/\", recursive = TRUE, full.names = TRUE)) |>\n  mutate(size_mb = file.size(files) * 1e-6) |>\n  summarize(n = n(),\n            min_mb = min(size_mb),\n            median_mb = median(size_mb),\n            max_mb = max(size_mb))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n      n min_mb median_mb max_mb\n  <int>  <dbl>     <dbl>  <dbl>\n1    11 0.0811      73.5   224.\n```\n\n\n:::\n:::\n\n\n\nNext we'll save the hit-level data. \n\nGet the basic hits table for all databases and join with the runs data, \nand save as feather for future use.\n\nThis may take a while (~2-5min per project, depending on the size). This also\ntakes a fair amount of disk space (much more than the SQLite databases).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(update) {\n  hits <- map(dbs, \\(x) tbl(x, \"hits\"))\n  \n  unlink(\"Data/Datasets/hits/*\", recursive = TRUE)\n  iwalk(hits, \\(x, i) {\n    message(i) \n    r <- select(runs[[i]], \"runID\", \"speciesID\", \"tagDeployID\", \"tagID\", \n                \"recvDeployID\", \"recvType\", \"motusFilter\")\n    x |>\n      mutate(proj_id = as.integer(i)) |>\n      left_join(r, by = \"runID\") |>\n      collect() |>\n      mutate(time = as_datetime(ts),\n             date = as_date(time),\n             month = month(date),\n             year = year(date),) |> \n      group_by(proj_id, speciesID, year) |>\n      write_dataset(path = \"Data/Datasets/hits/\", format = \"arrow\") \n  })\n}\n```\n:::\n\n\nAs with hits, we don't want files to be <20MB or >2GB and we want to avoid too many files (< 10,000).\n\nSo let's double check that we have reasonable file sizes and numbers.\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(files = list.files(\"Data/Datasets/hits/\", recursive = TRUE, full.names = TRUE)) |>\n  mutate(size_mb = file.size(files) * 1e-6) |>\n  summarize(n = n(),\n            min_mb = min(size_mb),\n            median_mb = median(size_mb),\n            max_mb = max(size_mb))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n      n  min_mb median_mb max_mb\n  <int>   <dbl>     <dbl>  <dbl>\n1   193 0.00363     0.995  5371.\n```\n\n\n:::\n:::\n\n\n\n\n## Wrap up\nDisconnect from the databases\n\n::: {.cell}\n\n```{.r .cell-code}\nwalk(dbs, dbDisconnect)\n```\n:::\n\n\n\n## Reproducibility\n\n\n:::{.callout-note collapse=true}\n### Session Info\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.3 (2024-02-29)\n os       Ubuntu 22.04.4 LTS\n system   x86_64, linux-gnu\n ui       X11\n language en_CA:en\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Winnipeg\n date     2024-04-24\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package       * version  date (UTC) lib source\n arrow         * 13.0.0.1 2023-09-22 [1] CRAN (R 4.3.1)\n assertr       * 3.0.0    2022-11-05 [1] CRAN (R 4.3.0)\n assertthat      0.2.1    2019-03-21 [1] CRAN (R 4.3.0)\n bit             4.0.5    2022-11-15 [1] CRAN (R 4.3.0)\n bit64           4.0.5    2020-08-30 [1] CRAN (R 4.3.0)\n blob            1.2.4    2023-03-17 [1] CRAN (R 4.3.0)\n cachem          1.0.8    2023-05-01 [1] CRAN (R 4.3.0)\n class           7.3-22   2023-05-03 [4] CRAN (R 4.3.1)\n classInt        0.4-10   2023-09-05 [1] CRAN (R 4.3.1)\n cli             3.6.2    2023-12-11 [1] CRAN (R 4.3.2)\n codetools       0.2-19   2023-02-01 [4] CRAN (R 4.2.2)\n colorspace      2.1-0    2023-01-23 [1] CRAN (R 4.3.0)\n DBI           * 1.2.2    2024-02-16 [1] CRAN (R 4.3.2)\n dbplyr          2.4.0    2023-10-26 [1] CRAN (R 4.3.1)\n devtools        2.4.5    2022-10-11 [1] CRAN (R 4.3.0)\n digest          0.6.34   2024-01-11 [1] CRAN (R 4.3.2)\n dplyr         * 1.1.4    2023-11-17 [1] CRAN (R 4.3.2)\n e1071           1.7-14   2023-12-06 [1] CRAN (R 4.3.2)\n ebirdst       * 3.2022.2 2024-01-15 [1] Github (ebird/ebirdst@bd409c7)\n ellipsis        0.3.2    2021-04-29 [1] CRAN (R 4.3.0)\n evaluate        0.23     2023-11-01 [1] CRAN (R 4.3.1)\n fansi           1.0.6    2023-12-08 [1] CRAN (R 4.3.2)\n fastmap         1.1.1    2023-02-24 [1] CRAN (R 4.3.0)\n forcats       * 1.0.0    2023-01-29 [1] CRAN (R 4.3.0)\n fs              1.6.3    2023-07-20 [1] CRAN (R 4.3.1)\n generics        0.1.3    2022-07-05 [1] CRAN (R 4.3.0)\n ggplot2       * 3.5.0    2024-02-23 [1] CRAN (R 4.3.2)\n ggrepel       * 0.9.5    2024-01-10 [1] CRAN (R 4.3.2)\n glue            1.7.0    2024-01-09 [1] CRAN (R 4.3.2)\n gt            * 0.10.0   2023-10-07 [1] CRAN (R 4.3.1)\n gtable          0.3.4    2023-08-21 [1] CRAN (R 4.3.1)\n hms             1.1.3    2023-03-21 [1] CRAN (R 4.3.0)\n htmltools       0.5.7    2023-11-03 [1] CRAN (R 4.3.1)\n htmlwidgets     1.6.4    2023-12-06 [1] CRAN (R 4.3.2)\n httpuv          1.6.14   2024-01-26 [1] CRAN (R 4.3.2)\n httr            1.4.7    2023-08-15 [1] CRAN (R 4.3.1)\n jsonlite        1.8.8    2023-12-04 [1] CRAN (R 4.3.2)\n KernSmooth      2.23-22  2023-07-10 [1] CRAN (R 4.3.1)\n knitr           1.45     2023-10-30 [1] CRAN (R 4.3.1)\n later           1.3.2    2023-12-06 [1] CRAN (R 4.3.2)\n lifecycle       1.0.4    2023-11-07 [1] CRAN (R 4.3.2)\n lubridate     * 1.9.3    2023-09-27 [1] CRAN (R 4.3.1)\n magrittr        2.0.3    2022-03-30 [1] CRAN (R 4.3.0)\n memoise         2.0.1    2021-11-26 [1] CRAN (R 4.3.0)\n mime            0.12     2021-09-28 [1] CRAN (R 4.3.0)\n miniUI          0.1.1.1  2018-05-18 [1] CRAN (R 4.3.0)\n motus         * 6.1.0    2024-02-01 [1] Github (motuswts/motus@9d99ed5)\n munsell         0.5.0    2018-06-12 [1] CRAN (R 4.3.0)\n naturecounts    0.4.0    2023-06-20 [1] local\n pillar          1.9.0    2023-03-22 [1] CRAN (R 4.3.0)\n pkgbuild        1.4.3    2023-12-10 [1] CRAN (R 4.3.2)\n pkgconfig       2.0.3    2019-09-22 [1] CRAN (R 4.3.0)\n pkgload         1.3.3    2023-09-22 [1] CRAN (R 4.3.1)\n profvis         0.3.8    2023-05-02 [1] CRAN (R 4.3.1)\n promises        1.2.1    2023-08-10 [1] CRAN (R 4.3.1)\n proxy           0.4-27   2022-06-09 [1] CRAN (R 4.3.0)\n purrr         * 1.0.2    2023-08-10 [1] CRAN (R 4.3.1)\n R6              2.5.1    2021-08-19 [1] CRAN (R 4.3.0)\n Rcpp            1.0.12   2024-01-09 [1] CRAN (R 4.3.2)\n readr         * 2.1.5    2024-01-10 [1] CRAN (R 4.3.2)\n remotes         2.4.2.1  2023-07-18 [1] CRAN (R 4.3.2)\n rlang           1.1.3    2024-01-10 [1] CRAN (R 4.3.2)\n rmarkdown       2.25     2023-09-18 [1] CRAN (R 4.3.1)\n rnaturalearth * 1.0.1    2023-12-15 [1] CRAN (R 4.3.2)\n RSQLite         2.3.5    2024-01-21 [1] CRAN (R 4.3.2)\n rstudioapi      0.15.0   2023-07-07 [1] CRAN (R 4.3.1)\n scales          1.3.0    2023-11-28 [1] CRAN (R 4.3.2)\n sessioninfo     1.2.2    2021-12-06 [1] CRAN (R 4.3.0)\n sf            * 1.0-15   2023-12-18 [1] CRAN (R 4.3.2)\n shiny           1.8.0    2023-11-17 [1] CRAN (R 4.3.2)\n stringi         1.8.3    2023-12-11 [1] CRAN (R 4.3.2)\n stringr       * 1.5.1    2023-11-14 [1] CRAN (R 4.3.2)\n terra           1.7-71   2024-01-31 [1] CRAN (R 4.3.2)\n tibble        * 3.2.1    2023-03-20 [1] CRAN (R 4.3.0)\n tidyr         * 1.3.1    2024-01-24 [1] CRAN (R 4.3.2)\n tidyselect      1.2.0    2022-10-10 [1] CRAN (R 4.3.0)\n timechange      0.3.0    2024-01-18 [1] CRAN (R 4.3.2)\n tzdb            0.4.0    2023-05-12 [1] CRAN (R 4.3.1)\n units         * 0.8-5    2023-11-28 [1] CRAN (R 4.3.2)\n urlchecker      1.0.1    2021-11-30 [1] CRAN (R 4.3.0)\n usethis         2.2.2    2023-07-06 [1] CRAN (R 4.3.1)\n utf8            1.2.4    2023-10-22 [1] CRAN (R 4.3.1)\n vctrs           0.6.5    2023-12-01 [1] CRAN (R 4.3.2)\n withr           3.0.0    2024-01-16 [1] CRAN (R 4.3.2)\n xfun            0.42     2024-02-08 [1] CRAN (R 4.3.2)\n xml2            1.3.6    2023-12-04 [1] CRAN (R 4.3.2)\n xtable          1.8-4    2019-04-21 [1] CRAN (R 4.3.0)\n yaml            2.3.8    2023-12-11 [1] CRAN (R 4.3.2)\n\n [1] /home/steffi/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n:::\n\n",
    "supporting": [
      "02_download_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}