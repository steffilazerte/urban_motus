---
title: Fine-scale Filtering
freeze: auto
---

Here we perform fine-scale filtering which involves more assessments of potential issues. 

Many of these steps rely on hit-level data, as opposed to run-level data from the
previous steps.

## Setup
```{r}
#| message: false
#| cache: false
source("XX_setup.R")
noise_runs <- open_dataset("Data/Datasets/noise_runs.feather", format = "feather")

runs <- open_dataset("Data/Datasets/runs", format = "feather") |>
  anti_join(noise_runs)

hits <- map(hits, \(x) {
  anti_join(x, noise_runs, by = c("runID", "recvDeployID", "tagDeployID")) |>
    left_join(select(runs, "runID", "recvType"), by = "runID")
})
  
```

We'll also use a modified version of the motusFilter[^1], such that 
hits from SENSORGNOME stations with a `freqSD > 0.1` will be considered 'bad' data 
(i.e., we'll set the motusFilter value to 0 for these hits).

[^1]: Based on notes from Amie MacDonald's scripts

```{r}
hits <- map(hits, \(x) {
  mutate(x, motusFilter = if_else(recvType == "SENSORGNOME" & freqSD > 0.1, 0, motusFilter))
})
```



## Bad Tags[^1]

First, we'll collect individual tags which have *only* bad data (i.e. all 0)

```{r}
noise_tags <- map(hits, \(x) {
  noise <- x |>
    select("tagID", "tagDeployID", "motusFilter") |>
    summarize(motusFilter = sum(motusFilter, na.rm = TRUE), .by = c("tagID", "tagDeployID")) |>
    filter(motusFilter == 0)
  
  semi_join(x, noise, by = c("tagID", "tagDeployID")) |>
    select("runID", "tagDeployID", "recvDeployID") |>
    collect()
}) |> list_rbind()
```

## Bad Runs[^1]

Now we'll calculate the proportion of good/bad data per tag, per receiver, per day. 

- We'll omit all runs on a day for this tag/receiver combo where less than half are 'good'
   
```{r}
noise_quality <- map(hits, \(x) {
  noise <- x |>
    select("date", "runID", "tagID", "tagDeployID", "recvDeployID", "motusFilter") |>
    summarize(p_good = sum(motusFilter, na.rm = TRUE) / n(),
              .by = c("tagID", "tagDeployID", "recvDeployID", "date")) |>
    filter(p_good <= 0.5) |>
    distinct()
  
  semi_join(x, noise, by = c("tagID", "tagDeployID", "recvDeployID", "date")) |>
    select("runID", "tagDeployID", "recvDeployID") |>
    collect()
}) |> list_rbind()
  
```
## Ambiguous detections

Let's collect all runs where there is some ambiguity. We'll look at the `allruns` table for this.
```{r}
ambig_ids <- map(dbs, \(x) {
  t <- tbl(x, "allruns") |>
    filter(!is.na(ambigID)) |>
    select("runID", "tagID" = "motusTagID", "ambigID") |>
    distinct() |>
    collect() |>
    mutate(is_ambig = TRUE)
  if(nrow(t) == 0) t <- NULL
  t
})|> 
  list_rbind(names_to = "proj_id") |>
  mutate(proj_id = as.integer(proj_id))
```

Now let's see if any of these runs are even left in our data after filtering...
```{r}
runs |>
  anti_join(noise_tags) |>
  anti_join(noise_quality) |>
  semi_join(ambig_ids) |>
  collect()
```

There are no ambiguous runs left the data after we cleaned, so we'll just ignore them for now.


## Looking at the filters
```{r}
noise_hits <- bind_rows(noise_tags, noise_quality) |>
  select("runID", "tagDeployID", "recvDeployID") |>
  distinct()

noise_hits
```

Next we'll take a look at how this compares to the motusFilter

With only the runs filtering
```{r}
count(runs, proj_id, motusFilter) |>
  collect() |>
  pivot_wider(names_from = motusFilter, values_from = n) |>
  arrange(proj_id)
```

With both the runs and hit filtering
```{r}
anti_join(runs, noise_hits, by = c("runID", "tagDeployID", "recvDeployID")) |>
  count(proj_id, motusFilter) |>
  collect() |>
  pivot_wider(names_from = motusFilter, values_from = n) |>
  arrange(proj_id)
```

There are still many 'bad' data according to the motusFilter... but we are 
definitely getting closer.


## Saving filters

We'll save the 'bad data' for use in the next steps.

```{r}
write_feather(noise_hits, sink = "Data/Datasets/noise_hits.feather")
```

## Wrap up
Disconnect from the databases
```{r}
walk(dbs, dbDisconnect)
```

## Reproducibility
{{< include _reproducibility.qmd >}}

